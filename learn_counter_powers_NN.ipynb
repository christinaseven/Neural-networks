{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEPS\n",
    "# read data from file (.npy)\n",
    "# shuffle rows (dim = 0)\n",
    "# cut into train and test (test = data[0:30], train = data[30:])\n",
    "# split into inputs and outputs (x = train[:,0:2], y = train[:,3]) for both train and test\n",
    "# end up with x, y, x_test, y_test which are torch tensors # x = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Christina'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from file (.npy)\n",
    "#data = np.loadtxt(\"data.txt\")\n",
    "#print(data.shape)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126221</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>20820</td>\n",
       "      <td>4996.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197866</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>757741</td>\n",
       "      <td>11461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126221</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>2082</td>\n",
       "      <td>14996.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197466</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>76774</td>\n",
       "      <td>12461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126221</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>2082</td>\n",
       "      <td>15996.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>193866</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>77774</td>\n",
       "      <td>13461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>126021</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>2082</td>\n",
       "      <td>14896.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>193866</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>7774</td>\n",
       "      <td>12461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>126621</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>2082</td>\n",
       "      <td>14596.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>192866</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>7574</td>\n",
       "      <td>10461.930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       c1     c2     c3      c4     target\n",
       "0  126221  86905  24564   20820   4996.608\n",
       "1  197866  86905  24564  757741  11461.930\n",
       "2  126221  86905  24564    2082  14996.608\n",
       "3  197466  86905  24564   76774  12461.930\n",
       "4  126221  86905  24564    2082  15996.608\n",
       "5  193866  86905  24564   77774  13461.930\n",
       "6  126021  86905  24564    2082  14896.608\n",
       "7  193866  86905  24564    7774  12461.930\n",
       "8  126621  86905  24564    2082  14596.608\n",
       "9  192866  86905  24564    7574  10461.930"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\Christina\\\\mydata.txt',names=['c1', 'c2','c3','c4','target'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>192866</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>7574</td>\n",
       "      <td>10461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197866</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>757741</td>\n",
       "      <td>11461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>193866</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>7774</td>\n",
       "      <td>12461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>126621</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>2082</td>\n",
       "      <td>14596.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>193866</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>77774</td>\n",
       "      <td>13461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126221</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>2082</td>\n",
       "      <td>15996.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>126021</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>2082</td>\n",
       "      <td>14896.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126221</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>2082</td>\n",
       "      <td>14996.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197466</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>76774</td>\n",
       "      <td>12461.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126221</td>\n",
       "      <td>86905</td>\n",
       "      <td>24564</td>\n",
       "      <td>20820</td>\n",
       "      <td>4996.608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       c1     c2     c3      c4     target\n",
       "9  192866  86905  24564    7574  10461.930\n",
       "1  197866  86905  24564  757741  11461.930\n",
       "7  193866  86905  24564    7774  12461.930\n",
       "8  126621  86905  24564    2082  14596.608\n",
       "5  193866  86905  24564   77774  13461.930\n",
       "4  126221  86905  24564    2082  15996.608\n",
       "6  126021  86905  24564    2082  14896.608\n",
       "2  126221  86905  24564    2082  14996.608\n",
       "3  197466  86905  24564   76774  12461.930\n",
       "0  126221  86905  24564   20820   4996.608"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle rows (dim = 0)\n",
    "data = data.iloc[np.random.permutation(len(data))]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in X, y\n",
    "#X = data[:,0:4]\n",
    "#y = data[:,4]\n",
    "array=data.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut into train and test (test = data[0:30], train = data[30:])\n",
    "X_train = X[0:7, :]\n",
    "y_train = y[0:7]\n",
    "X_test = X[7:,:]\n",
    "y_test = y[7:]\n",
    "\n",
    "#X_train=X_train.astype(np.float32)\n",
    "#y_train=y_train.astype(np.float32)\n",
    "#X_test=X_test.astype(np.float32)\n",
    "#y_test=y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[192866.,  86905.,  24564.,   7574.],\n",
       "         [197866.,  86905.,  24564., 757741.],\n",
       "         [193866.,  86905.,  24564.,   7774.],\n",
       "         [126621.,  86905.,  24564.,   2082.],\n",
       "         [193866.,  86905.,  24564.,  77774.],\n",
       "         [126221.,  86905.,  24564.,   2082.],\n",
       "         [126021.,  86905.,  24564.,   2082.]], dtype=torch.float64),\n",
       " tensor([10461.9300, 12461.9300, 14996.6080, 15996.6080, 12461.9300, 11461.9300,\n",
       "         14596.6080], dtype=torch.float64),\n",
       " tensor([[126221.,  86905.,  24564.,   2082.],\n",
       "         [197466.,  86905.,  24564.,  76774.],\n",
       "         [126221.,  86905.,  24564.,  20820.]], dtype=torch.float64),\n",
       " tensor([14896.6080, 13461.9300, 14996.6080], dtype=torch.float64))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch tensors in order to put them in NN\n",
    "X_train= torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model 1\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()                          #n_feature = 1 (the ti of each yi)\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer (n_hidden = neurons of hidden layer)\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer (n_output=1, the correspoding yi of ti)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(n_feature=4, n_hidden=3, n_output=1)   #200 hidden neurons, \n",
    "#to n_feature einai ta inputs x_train gia ta opoia exw to y_train(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "net = net.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8452e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6758e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6905e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5581e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6338e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6213e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5421e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6667e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5471e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6002e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6070e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5315e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6141e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5577e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5489e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5940e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5332e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5640e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5671e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5297e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5658e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5457e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5349e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5590e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5339e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5402e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5490e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5295e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5430e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5395e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5300e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5420e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5327e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5325e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5385e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5296e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5343e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5343e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5292e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5346e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5308e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5303e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5331e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5291e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5314e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5310e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5291e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5314e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5293e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5298e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5304e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5288e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5302e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5292e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5291e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5298e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5287e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5295e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5289e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5288e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5292e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5286e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5291e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5287e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5287e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5288e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5284e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5288e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5284e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5286e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5285e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5284e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5285e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5283e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5284e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5283e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5283e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5283e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5282e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5283e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5281e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5282e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5281e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5281e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5281e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5280e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5280e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5280e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5280e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5279e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5279e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5279e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5279e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5278e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5278e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5278e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5278e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5278e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5277e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5277e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5277e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5277e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5276e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5276e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5276e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5276e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5275e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5275e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5275e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5275e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5275e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5274e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5274e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5274e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5274e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5273e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5273e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5273e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5273e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5273e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5272e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5272e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5272e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5272e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5271e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5271e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5271e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5271e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5270e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5270e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5270e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5270e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5270e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5269e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5269e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5269e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5269e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5268e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5268e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5268e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5268e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5268e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5267e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5267e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5267e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5267e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5266e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5266e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5266e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5266e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5266e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5265e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5265e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5265e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5265e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5264e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5264e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5264e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5264e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5264e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5263e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5263e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5263e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5263e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5262e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5262e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5262e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5262e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5261e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5261e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5261e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5261e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5261e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5260e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5260e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5260e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5260e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5259e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5259e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5259e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5259e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5259e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5258e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5258e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5258e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5258e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5257e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5257e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5257e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5257e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5257e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5256e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5256e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5256e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5256e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5255e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5255e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5255e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5255e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5255e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5254e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5254e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5254e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5254e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5253e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5253e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5253e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5253e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5252e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5252e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5252e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5252e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5252e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5251e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5251e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5251e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5251e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5250e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5250e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5250e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5250e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5250e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5249e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5249e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5249e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5249e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5248e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5248e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5248e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5248e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5248e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5247e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5247e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5247e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5247e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5246e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5246e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5246e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5246e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5245e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5245e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5245e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5245e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5245e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5244e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5244e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5244e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5244e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5243e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5243e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5243e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5243e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5243e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5242e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5242e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5242e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5242e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5241e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5241e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5241e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5241e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5241e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5240e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5240e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5240e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5240e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5239e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5239e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5239e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5239e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5239e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5238e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5238e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5238e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5238e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5237e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5237e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5237e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5237e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5236e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5236e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5236e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5236e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5236e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5235e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5235e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5235e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5235e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5234e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5234e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5234e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5234e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5234e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5233e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5233e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5233e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5233e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5232e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5232e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5232e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5232e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5232e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5231e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5231e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5231e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5231e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5230e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5230e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5230e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5230e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5230e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5229e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5229e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5229e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5229e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5228e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5228e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5228e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5228e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5227e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5227e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5227e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5227e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5227e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5226e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5226e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5226e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5226e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5225e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5225e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5225e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5225e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5225e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5224e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5224e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5224e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5224e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5223e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5223e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5223e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5223e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5223e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5222e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5222e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5222e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5222e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5221e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5221e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5221e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5221e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5221e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5220e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5220e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5220e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5220e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5219e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5219e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5219e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5219e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5218e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5218e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5218e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5218e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5218e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5217e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5217e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5217e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5217e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5216e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5216e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5216e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5216e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5216e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5215e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5215e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5215e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5215e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5214e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5214e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5214e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5214e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5214e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5213e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5213e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5213e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5213e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5212e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5212e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5212e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5212e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5212e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5211e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5211e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5211e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5211e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5210e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5210e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5210e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5210e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5208e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5208e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5208e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5208e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5207e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5207e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5207e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5207e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5207e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5206e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5206e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5206e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5206e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5205e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5205e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5205e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5205e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5205e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5204e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5204e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5204e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5204e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5203e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5203e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5203e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5203e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5203e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5202e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5202e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5202e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5202e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5201e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5201e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5201e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5201e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5200e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5200e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5200e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5200e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5200e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5199e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5199e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5199e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5199e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5198e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5198e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5198e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5198e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5198e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5197e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5197e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5197e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5197e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5197e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5196e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5196e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5197e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5198e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5200e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5206e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5220e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5249e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5310e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5430e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5580e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5687e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5455e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5203e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5301e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5338e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5194e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5282e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5221e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5227e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5232e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5210e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5223e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5203e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5213e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5206e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5200e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5208e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5192e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5208e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5190e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5202e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5193e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5193e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5197e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5188e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5195e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5190e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5190e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5192e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5187e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5191e+08, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "EPOCHS = 500\n",
    "epochs = EPOCHS\n",
    "\n",
    "for t in range(epochs):\n",
    "  \n",
    "    y_pred = net(X_train.float())     # input x and prediction of the model based on x\n",
    "\n",
    "    loss = loss_func(y_pred, y_train.float())     # must be (1. nn output, 2. target)\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()   # clear gradients for next epoch\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model 2\n",
    "net2 = torch.nn.Sequential(\n",
    "        torch.nn.Linear(4, 3),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(3, 1),\n",
    "    )\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.5)\n",
    "loss_func = torch.nn.MSELoss() \n",
    "net2 = net2.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0209e+08, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "# start training\n",
    "for t in range(500):\n",
    "  \n",
    "    prediction = net2(X_train.float())     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y_train.float())     \n",
    "    print(loss)\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(x_test)\n",
    "pred2 = net2(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(pred, y_test)#oso pio xamilo einai to loss toso kaliteri einai i proseggisi\n",
    "loss2 = loss_func(pred2, y_test)\n",
    "float(loss)\n",
    "float(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = net(counters)#prepei na einai tensor tis morfis (1, 3) me integers\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
